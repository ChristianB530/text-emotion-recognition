import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# Machine Learning imports
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.metrics import precision_recall_curve, average_precision_score
from sklearn.preprocessing import LabelEncoder
from sklearn.utils.class_weight import compute_class_weight

# Deep Learning imports
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F

# Set random seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)


class EmotionDataLoader:
    """Loader for emotion recognition datasets"""
    
    def __init__(self):
        self.label_map = {
            0: 'sadness',
            1: 'joy', 
            2: 'love',
            3: 'anger',
            4: 'fear',
            5: 'surprise'
        }
    
    def load_emotion_dataset(self):
        """Load the Emotion Dataset from Kaggle with 6 labels"""
        try:
            train_df = pd.read_csv('training.csv')
            val_df = pd.read_csv('validation.csv')
            test_df = pd.read_csv('test.csv')
            
            print("Emotion Dataset loaded successfully!")
            print(f"Training samples: {len(train_df):,}")
            print(f"Validation samples: {len(val_df):,}")
            print(f"Test samples: {len(test_df):,}")
            
            # Show dataset statistics
            #self._show_dataset_stats(train_df, "Training")
            #self._show_dataset_stats(val_df, "Validation")
            #self._show_dataset_stats(test_df, "Test")
            
            return train_df, val_df, test_df
            
        except FileNotFoundError as e:
            print(f"Error loading dataset: {e}")
            return None, None, None
    

class BaselineModel:
    """
    Baseline Logistic Regression Model
    Simple, interpretable, and provides solid performance baseline
    """
    
    def __init__(self):
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            stop_words='english',
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.8
        )
        self.model = None
        self.label_encoder = LabelEncoder()
    
    def prepare_features(self, texts, fit=True):
        """Convert texts to TF-IDF features"""
        if fit:
            features = self.vectorizer.fit_transform(texts)
        else:
            features = self.vectorizer.transform(texts)
        return features
    
    def train(self, X_train, y_train, X_val, y_val):
        """Train the logistic regression baseline model"""
        print("Training Logistic Regression Baseline...")
        
        self.model = LogisticRegression(
            random_state=42,
            max_iter=1000,
            multi_class='multinomial',
            class_weight='balanced',
            C=1.0,
            n_jobs=-1
        )
        
        self.model.fit(X_train, y_train)
        
        # Validation performance
        y_pred_val = self.model.predict(X_val)
        val_accuracy = accuracy_score(y_val, y_pred_val)
        val_f1 = f1_score(y_val, y_pred_val, average='macro')
        
        print(f"Baseline Model Performance:")
        print(f"  Validation Accuracy: {val_accuracy:.4f}")
        print(f"  Validation Macro F1: {val_f1:.4f}")
        
        return self.model
    
    def predict(self, X):
        """Make predictions"""
        return self.model.predict(X)
    
    def predict_proba(self, X):
        """Get prediction probabilities"""
        return self.model.predict_proba(X)
    

# Initialize and load data
loader = EmotionDataLoader()
train_df, val_df, test_df = loader.load_emotion_dataset()

# Initialize BaselineModel
baseline = BaselineModel()

y_train = baseline.label_encoder.fit_transform(train_df['label'])
y_val = baseline.label_encoder.transform(val_df['label'])
y_test = baseline.label_encoder.transform(test_df['label'])
X_train = baseline.prepare_features(train_df['text'], fit=True)
X_val   = baseline.prepare_features(val_df['text'], fit=False)
X_test  = baseline.prepare_features(test_df['text'], fit=False)

model = baseline.train(X_train, y_train, X_val, y_val)

# Evaluate on test set
y_pred_test = baseline.predict(X_test)
target_names = [str(label) for label in baseline.label_encoder.inverse_transform(sorted(np.unique(y_test)))]
print(classification_report(y_test, y_pred_test, target_names=target_names))


# Predict on new data
sample_text = ["I am so sad! Lost my job today."]
sample_features = baseline.prepare_features(sample_text, fit=False)
prediction = baseline.predict(sample_features)
probabilities = baseline.predict_proba(sample_features)
print(probabilities)



